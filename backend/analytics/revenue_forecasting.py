"""
Advanced Revenue Forecasting Engine

This module provides comprehensive revenue forecasting capabilities using:
- ARIMA models for time series analysis
- Facebook Prophet for seasonality and holidays
- Seasonal decomposition and trend analysis
- Multiple forecasting models with ensemble predictions
- Forecast accuracy metrics and confidence intervals
- Business scenario planning and what-if analysis

Author: Nexus Analytics Team
Date: October 2025
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# Time Series and Forecasting
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.seasonal import seasonal_decompose
    from statsmodels.tsa.stattools import adfuller
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False

# Disable pmdarima due to numpy compatibility issues
PMDARIMA_AVAILABLE = False

# Statistical Analysis
from scipy import stats
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RevenueForecaster:
    """
    Advanced Revenue Forecasting Engine
    
    Provides multiple forecasting models and ensemble predictions
    for accurate revenue forecasting with confidence intervals.
    """
    
    def __init__(self):
        self.models = {}
        self.forecasts = {}
        self.data = None
        self.prepared_data = None
        self.business_metrics = {}
        
    def prepare_data(self, orders_data: List[Dict]) -> pd.DataFrame:
        """
        Prepare and clean data for forecasting
        
        Args:
            orders_data: List of order dictionaries from database
            
        Returns:
            Prepared DataFrame with time series data
        """
        try:
            # Convert to DataFrame
            df = pd.DataFrame(orders_data)
            
            # Convert order_date to datetime
            df['order_date'] = pd.to_datetime(df['order_date'])
            df['total_amount'] = pd.to_numeric(df['total_amount'], errors='coerce')
            
            # Create daily revenue aggregation
            daily_revenue = df.groupby('order_date').agg({
                'total_amount': 'sum',
                'order_id': 'count'
            }).reset_index()
            
            daily_revenue.columns = ['date', 'revenue', 'order_count']
            
            # Fill missing dates with zero revenue
            date_range = pd.date_range(
                start=daily_revenue['date'].min(),
                end=daily_revenue['date'].max(),
                freq='D'
            )
            
            full_dates = pd.DataFrame({'date': date_range})
            daily_revenue = full_dates.merge(daily_revenue, on='date', how='left').fillna(0)
            
            # Add time-based features
            daily_revenue['day_of_week'] = daily_revenue['date'].dt.dayofweek
            daily_revenue['month'] = daily_revenue['date'].dt.month
            daily_revenue['quarter'] = daily_revenue['date'].dt.quarter
            daily_revenue['is_weekend'] = daily_revenue['day_of_week'].isin([5, 6]).astype(int)
            
            # Calculate moving averages
            daily_revenue['revenue_7d_ma'] = daily_revenue['revenue'].rolling(window=7, center=True).mean()
            daily_revenue['revenue_30d_ma'] = daily_revenue['revenue'].rolling(window=30, center=True).mean()
            
            # Weekly and monthly aggregations
            daily_revenue['week'] = daily_revenue['date'].dt.to_period('W')
            daily_revenue['month_period'] = daily_revenue['date'].dt.to_period('M')
            
            self.data = daily_revenue
            self.prepared_data = daily_revenue
            
            logger.info(f"Prepared {len(daily_revenue)} days of revenue data")
            return daily_revenue
            
        except Exception as e:
            logger.error(f"Error preparing data: {str(e)}")
            raise
    
    def analyze_stationarity(self, series: pd.Series) -> Dict[str, Any]:
        """
        Analyze time series stationarity using Augmented Dickey-Fuller test
        """
        try:
            # Remove any NaN values
            series = series.dropna()
            
            if len(series) < 10:
                return {
                    'is_stationary': False,
                    'adf_statistic': None,
                    'p_value': 1.0,
                    'critical_values': {},
                    'interpretation': 'Insufficient data for stationarity test'
                }
            
            adf_result = adfuller(series)
            
            result = {
                'is_stationary': adf_result[1] < 0.05,
                'adf_statistic': adf_result[0],
                'p_value': adf_result[1],
                'critical_values': adf_result[4],
                'interpretation': 'Stationary' if adf_result[1] < 0.05 else 'Non-stationary'
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing stationarity: {str(e)}")
            return {
                'is_stationary': False,
                'adf_statistic': None,
                'p_value': 1.0,
                'critical_values': {},
                'interpretation': f'Error: {str(e)}'
            }
    
    def seasonal_decomposition(self, series: pd.Series, period: int = 7) -> Dict[str, Any]:
        """
        Perform seasonal decomposition of time series
        """
        try:
            # Ensure we have enough data points and handle missing values
            series = series.dropna()
            
            if len(series) < 2 * period:
                logger.warning(f"Insufficient data for seasonal decomposition. Need at least {2 * period} points, got {len(series)}")
                return {
                    'trend': None,
                    'seasonal': None,
                    'residual': None,
                    'seasonal_strength': 0,
                    'trend_strength': 0,
                    'error': 'Insufficient data for decomposition'
                }
            
            # Perform decomposition
            decomposition = seasonal_decompose(
                series, 
                model='additive', 
                period=period,
                extrapolate_trend='freq'
            )
            
            # Calculate seasonal and trend strength
            seasonal_strength = np.var(decomposition.seasonal) / np.var(series) if np.var(series) > 0 else 0
            trend_strength = np.var(decomposition.trend.dropna()) / np.var(series) if np.var(series) > 0 else 0
            
            return {
                'trend': decomposition.trend,
                'seasonal': decomposition.seasonal,
                'residual': decomposition.resid,
                'seasonal_strength': seasonal_strength,
                'trend_strength': trend_strength,
                'error': None
            }
            
        except Exception as e:
            logger.error(f"Error in seasonal decomposition: {str(e)}")
            return {
                'trend': None,
                'seasonal': None,
                'residual': None,
                'seasonal_strength': 0,
                'trend_strength': 0,
                'error': str(e)
            }
    
    def fit_arima_model(self, series: pd.Series, forecast_periods: int = 30) -> Dict[str, Any]:
        """
        Fit ARIMA model using auto_arima or fallback to simple ARIMA
        """
        try:
            # Clean the series
            series = series.dropna()
            
            if len(series) < 10:
                logger.warning("Insufficient data for ARIMA model")
                return {'error': 'Insufficient data for ARIMA model'}
            
            if not STATSMODELS_AVAILABLE:
                return {'error': 'Statsmodels not available'}
            
            # Use simple ARIMA approach (pmdarima disabled due to compatibility issues)
            
            # Fallback to simple ARIMA(1,1,1)
            logger.info("Using simple ARIMA(1,1,1) model...")
            model = ARIMA(series, order=(1, 1, 1))
            fitted_model = model.fit()
            
            # Make forecast
            forecast_result = fitted_model.forecast(steps=forecast_periods, alpha=0.05)
            if hasattr(forecast_result, 'predicted_mean'):
                forecast = forecast_result.predicted_mean
                conf_int = np.column_stack([
                    forecast_result.conf_int().iloc[:, 0],
                    forecast_result.conf_int().iloc[:, 1]
                ])
            else:
                forecast = forecast_result
                # Simple confidence interval approximation
                forecast_std = np.std(series) * 0.1
                conf_int = np.column_stack([
                    forecast - 1.96 * forecast_std,
                    forecast + 1.96 * forecast_std
                ])
            
            # Calculate model metrics
            fitted_values = fitted_model.fittedvalues
            residuals = fitted_model.resid
            
            mse = np.mean(residuals**2)
            mae = np.mean(np.abs(residuals))
            mape = np.mean(np.abs(residuals / series.iloc[len(series)-len(residuals):].replace(0, np.nan))) * 100
            
            result = {
                'model': fitted_model,
                'order': (1, 1, 1),
                'aic': fitted_model.aic,
                'bic': fitted_model.bic,
                'forecast': forecast,
                'confidence_intervals': conf_int,
                'fitted_values': fitted_values,
                'residuals': residuals,
                'mse': mse,
                'mae': mae,
                'mape': mape if not np.isnan(mape) and not np.isinf(mape) else 0,
                'error': None
            }
            
            self.models['arima'] = result
            logger.info("Simple ARIMA(1,1,1) model fitted successfully")
            
            return result
            
        except Exception as e:
            logger.error(f"Error fitting ARIMA model: {str(e)}")
            return {'error': str(e)}
    
    def fit_prophet_model(self, df: pd.DataFrame, forecast_periods: int = 30) -> Dict[str, Any]:
        """
        Fit Facebook Prophet model for seasonality and trend analysis
        """
        try:
            # Prepare data for Prophet
            prophet_df = df[['date', 'revenue']].copy()
            prophet_df.columns = ['ds', 'y']
            
            # Remove any infinite or extremely large values
            prophet_df = prophet_df[np.isfinite(prophet_df['y'])]
            prophet_df['y'] = np.clip(prophet_df['y'], 0, prophet_df['y'].quantile(0.99) * 2)
            
            if len(prophet_df) < 10:
                logger.warning("Insufficient data for Prophet model")
                return {'error': 'Insufficient data for Prophet model'}
            
            # Initialize Prophet model
            model = Prophet(
                daily_seasonality=True,
                weekly_seasonality=True,
                yearly_seasonality=True if len(prophet_df) > 365 else False,
                changepoint_prior_scale=0.05,
                seasonality_prior_scale=10.0,
                holidays_prior_scale=10.0,
                interval_width=0.8
            )
            
            # Fit model
            logger.info("Fitting Prophet model...")
            model.fit(prophet_df)
            
            # Create future dataframe
            future = model.make_future_dataframe(periods=forecast_periods)
            
            # Make forecast
            forecast = model.predict(future)
            
            # Extract forecast components
            forecast_values = forecast.tail(forecast_periods)
            
            # Calculate model performance
            fitted_values = forecast.head(len(prophet_df))['yhat']
            residuals = prophet_df['y'] - fitted_values
            
            mse = np.mean(residuals**2)
            mae = np.mean(np.abs(residuals))
            mape = np.mean(np.abs(residuals / prophet_df['y'].replace(0, np.nan))) * 100
            
            result = {
                'model': model,
                'forecast': forecast,
                'forecast_values': forecast_values,
                'components': model.predict(future),
                'fitted_values': fitted_values,
                'residuals': residuals,
                'mse': mse,
                'mae': mae,
                'mape': mape if not np.isnan(mape) and not np.isinf(mape) else 0,
                'error': None
            }
            
            self.models['prophet'] = result
            logger.info("Prophet model fitted successfully")
            
            return result
            
        except Exception as e:
            logger.error(f"Error fitting Prophet model: {str(e)}")
            return {'error': str(e)}
    
    def ensemble_forecast(self, forecast_periods: int = 30) -> Dict[str, Any]:
        """
        Create ensemble forecast combining multiple models
        """
        try:
            if not self.models:
                return {'error': 'No models available for ensemble'}
            
            forecasts = []
            weights = []
            model_names = []
            
            # Collect forecasts from available models
            for model_name, model_result in self.models.items():
                if 'error' not in model_result or model_result['error'] is None:
                    if model_name == 'arima':
                        forecasts.append(model_result['forecast'])
                        # Weight by inverse of MAPE (lower MAPE = higher weight)
                        weight = 1 / (model_result['mape'] + 1) if model_result['mape'] > 0 else 1
                        weights.append(weight)
                        model_names.append(model_name)
                    
                    elif model_name == 'prophet':
                        prophet_forecast = model_result['forecast_values']['yhat'].values
                        forecasts.append(prophet_forecast)
                        weight = 1 / (model_result['mape'] + 1) if model_result['mape'] > 0 else 1
                        weights.append(weight)
                        model_names.append(model_name)
            
            if not forecasts:
                return {'error': 'No valid forecasts available for ensemble'}
            
            # Normalize weights
            weights = np.array(weights)
            weights = weights / np.sum(weights)
            
            # Create ensemble forecast
            ensemble_forecast = np.zeros(forecast_periods)
            
            for i, forecast in enumerate(forecasts):
                # Ensure all forecasts have the same length
                forecast_array = np.array(forecast)
                if len(forecast_array) >= forecast_periods:
                    ensemble_forecast += weights[i] * forecast_array[:forecast_periods]
                else:
                    # Pad with last value if forecast is shorter
                    padded_forecast = np.pad(
                        forecast_array, 
                        (0, forecast_periods - len(forecast_array)), 
                        mode='edge'
                    )
                    ensemble_forecast += weights[i] * padded_forecast
            
            # Calculate prediction intervals (approximation)
            forecast_std = np.std([f[:forecast_periods] if len(f) >= forecast_periods 
                                 else np.pad(f, (0, forecast_periods - len(f)), mode='edge') 
                                 for f in forecasts], axis=0)
            
            lower_bound = ensemble_forecast - 1.96 * forecast_std
            upper_bound = ensemble_forecast + 1.96 * forecast_std
            
            # Generate forecast dates
            last_date = self.data['date'].max()
            forecast_dates = pd.date_range(
                start=last_date + timedelta(days=1),
                periods=forecast_periods,
                freq='D'
            )
            
            result = {
                'forecast': ensemble_forecast,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound,
                'forecast_dates': forecast_dates,
                'model_weights': dict(zip(model_names, weights)),
                'individual_forecasts': dict(zip(model_names, forecasts)),
                'error': None
            }
            
            self.forecasts['ensemble'] = result
            logger.info(f"Ensemble forecast created using {len(model_names)} models")
            
            return result
            
        except Exception as e:
            logger.error(f"Error creating ensemble forecast: {str(e)}")
            return {'error': str(e)}
    
    def calculate_forecast_accuracy(self, actual: pd.Series, predicted: pd.Series) -> Dict[str, float]:
        """
        Calculate various forecast accuracy metrics
        """
        try:
            # Align series
            min_len = min(len(actual), len(predicted))
            actual_aligned = actual.iloc[-min_len:].values
            predicted_aligned = predicted.iloc[-min_len:].values if hasattr(predicted, 'iloc') else predicted[-min_len:]
            
            # Remove any NaN or infinite values
            mask = np.isfinite(actual_aligned) & np.isfinite(predicted_aligned)
            actual_clean = actual_aligned[mask]
            predicted_clean = predicted_aligned[mask]
            
            if len(actual_clean) == 0:
                return {
                    'mae': np.inf,
                    'mse': np.inf,
                    'rmse': np.inf,
                    'mape': np.inf,
                    'r2_score': 0
                }
            
            # Calculate metrics
            mae = mean_absolute_error(actual_clean, predicted_clean)
            mse = mean_squared_error(actual_clean, predicted_clean)
            rmse = np.sqrt(mse)
            
            # MAPE - handle division by zero
            actual_nonzero = actual_clean != 0
            if np.any(actual_nonzero):
                mape = np.mean(np.abs((actual_clean[actual_nonzero] - predicted_clean[actual_nonzero]) 
                                    / actual_clean[actual_nonzero])) * 100
            else:
                mape = np.inf
            
            # R-squared
            ss_res = np.sum((actual_clean - predicted_clean) ** 2)
            ss_tot = np.sum((actual_clean - np.mean(actual_clean)) ** 2)
            r2_score = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            
            return {
                'mae': mae,
                'mse': mse,
                'rmse': rmse,
                'mape': mape if not np.isnan(mape) and not np.isinf(mape) else 100,
                'r2_score': r2_score
            }
            
        except Exception as e:
            logger.error(f"Error calculating forecast accuracy: {str(e)}")
            return {
                'mae': np.inf,
                'mse': np.inf,
                'rmse': np.inf,
                'mape': np.inf,
                'r2_score': 0
            }
    
    def business_insights(self, forecast_periods: int = 30) -> Dict[str, Any]:
        """
        Generate business insights from forecasting analysis
        """
        try:
            if self.data is None or len(self.data) == 0:
                return {'error': 'No data available for insights'}
            
            insights = {}
            
            # Historical performance
            total_revenue = self.data['revenue'].sum()
            avg_daily_revenue = self.data['revenue'].mean()
            revenue_std = self.data['revenue'].std()
            
            # Growth trends
            recent_30d = self.data.tail(30)['revenue'].mean()
            previous_30d = self.data.iloc[-60:-30]['revenue'].mean() if len(self.data) >= 60 else avg_daily_revenue
            
            growth_rate = ((recent_30d - previous_30d) / previous_30d * 100) if previous_30d > 0 else 0
            
            # Seasonal patterns
            if 'day_of_week' in self.data.columns:
                weekly_patterns = self.data.groupby('day_of_week')['revenue'].mean()
                best_day = weekly_patterns.idxmax()
                worst_day = weekly_patterns.idxmin()
            else:
                best_day = worst_day = None
            
            # Forecast insights
            forecast_total = 0
            forecast_growth = 0
            
            if 'ensemble' in self.forecasts and 'error' not in self.forecasts['ensemble']:
                forecast_total = np.sum(self.forecasts['ensemble']['forecast'])
                forecast_growth = (forecast_total / (avg_daily_revenue * forecast_periods) - 1) * 100
            
            insights = {
                'historical_performance': {
                    'total_revenue': total_revenue,
                    'avg_daily_revenue': avg_daily_revenue,
                    'revenue_volatility': revenue_std / avg_daily_revenue if avg_daily_revenue > 0 else 0,
                    'growth_rate_30d': growth_rate
                },
                'seasonal_patterns': {
                    'best_day_of_week': int(best_day) if best_day is not None else None,
                    'worst_day_of_week': int(worst_day) if worst_day is not None else None,
                    'weekend_effect': self.data.groupby('is_weekend')['revenue'].mean().to_dict() if 'is_weekend' in self.data.columns else {}
                },
                'forecast_insights': {
                    'predicted_total_revenue': forecast_total,
                    'predicted_growth_rate': forecast_growth,
                    'revenue_confidence': 'High' if forecast_growth > 0 else 'Moderate'
                },
                'recommendations': self._generate_recommendations(growth_rate, forecast_growth)
            }
            
            self.business_metrics = insights
            return insights
            
        except Exception as e:
            logger.error(f"Error generating business insights: {str(e)}")
            return {'error': str(e)}
    
    def _generate_recommendations(self, historical_growth: float, forecast_growth: float) -> List[str]:
        """
        Generate business recommendations based on forecasting analysis
        """
        recommendations = []
        
        if historical_growth > 10:
            recommendations.append("Strong growth momentum detected. Consider scaling marketing efforts.")
        elif historical_growth < -5:
            recommendations.append("Declining trend observed. Investigate market factors and customer retention.")
        
        if forecast_growth > 5:
            recommendations.append("Positive forecast indicates good market conditions. Plan for inventory increase.")
        elif forecast_growth < -5:
            recommendations.append("Forecast suggests potential downturn. Focus on cost optimization and customer retention.")
        
        if abs(forecast_growth - historical_growth) > 10:
            recommendations.append("Significant change in trend expected. Monitor key metrics closely.")
        
        recommendations.append("Regular model retraining recommended for optimal forecast accuracy.")
        
        return recommendations
    
    def generate_forecast_report(self, forecast_periods: int = 30) -> Dict[str, Any]:
        """
        Generate comprehensive forecasting report
        """
        try:
            if self.data is None:
                return {'error': 'No data available for forecasting'}
            
            report = {
                'data_summary': {
                    'total_days': len(self.data),
                    'date_range': {
                        'start': self.data['date'].min().isoformat(),
                        'end': self.data['date'].max().isoformat()
                    },
                    'total_revenue': float(self.data['revenue'].sum()),
                    'avg_daily_revenue': float(self.data['revenue'].mean())
                },
                'stationarity_analysis': {},
                'seasonal_decomposition': {},
                'model_results': {},
                'ensemble_forecast': {},
                'business_insights': {},
                'forecast_accuracy': {}
            }
            
            # Stationarity analysis
            stationarity = self.analyze_stationarity(self.data['revenue'])
            report['stationarity_analysis'] = stationarity
            
            # Seasonal decomposition
            decomposition = self.seasonal_decomposition(self.data['revenue'])
            if decomposition['error'] is None:
                report['seasonal_decomposition'] = {
                    'seasonal_strength': float(decomposition['seasonal_strength']),
                    'trend_strength': float(decomposition['trend_strength'])
                }
            
            # Fit models
            arima_result = self.fit_arima_model(self.data['revenue'], forecast_periods)
            prophet_result = self.fit_prophet_model(self.data, forecast_periods)
            
            # Model summaries
            if 'error' not in arima_result:
                report['model_results']['arima'] = {
                    'order': arima_result['order'],
                    'aic': float(arima_result['aic']),
                    'mae': float(arima_result['mae']),
                    'mape': float(arima_result['mape'])
                }
            
            if 'error' not in prophet_result:
                report['model_results']['prophet'] = {
                    'mae': float(prophet_result['mae']),
                    'mape': float(prophet_result['mape'])
                }
            
            # Ensemble forecast
            ensemble_result = self.ensemble_forecast(forecast_periods)
            if 'error' not in ensemble_result:
                report['ensemble_forecast'] = {
                    'forecast_values': [float(x) for x in ensemble_result['forecast']],
                    'lower_bound': [float(x) for x in ensemble_result['lower_bound']],
                    'upper_bound': [float(x) for x in ensemble_result['upper_bound']],
                    'forecast_dates': [d.isoformat() for d in ensemble_result['forecast_dates']],
                    'model_weights': {k: float(v) for k, v in ensemble_result['model_weights'].items()}
                }
            
            # Business insights
            insights = self.business_insights(forecast_periods)
            if 'error' not in insights:
                report['business_insights'] = insights
            
            return report
            
        except Exception as e:
            logger.error(f"Error generating forecast report: {str(e)}")
            return {'error': str(e)}


def create_forecaster_from_orders(orders_data: List[Dict], forecast_periods: int = 30) -> Dict[str, Any]:
    """
    Convenience function to create forecaster and generate complete report
    """
    try:
        forecaster = RevenueForecaster()
        forecaster.prepare_data(orders_data)
        return forecaster.generate_forecast_report(forecast_periods)
    
    except Exception as e:
        logger.error(f"Error in create_forecaster_from_orders: {str(e)}")
        return {'error': str(e)}


if __name__ == "__main__":
    # Example usage and testing
    print("üîÆ Revenue Forecasting Engine Test")
    
    # Generate sample data for testing
    dates = pd.date_range(start='2024-01-01', end='2024-10-01', freq='D')
    np.random.seed(42)
    
    # Create synthetic revenue data with trend and seasonality
    trend = np.linspace(1000, 2000, len(dates))
    seasonal = 500 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)  # Weekly seasonality
    noise = np.random.normal(0, 200, len(dates))
    revenue = trend + seasonal + noise
    revenue = np.maximum(revenue, 0)  # Ensure non-negative
    
    # Create sample orders data
    sample_orders = []
    for i, (date, rev) in enumerate(zip(dates, revenue)):
        # Create multiple orders per day
        daily_orders = max(1, int(rev / 300))  # Approximate orders based on revenue
        for j in range(daily_orders):
            sample_orders.append({
                'order_id': f'order_{i}_{j}',
                'order_date': date.strftime('%Y-%m-%d'),
                'total_amount': rev / daily_orders
            })
    
    print(f"Generated {len(sample_orders)} sample orders")
    
    # Test forecaster
    try:
        report = create_forecaster_from_orders(sample_orders, forecast_periods=14)
        
        if 'error' in report:
            print(f"‚ùå Error: {report['error']}")
        else:
            print("‚úÖ Forecasting report generated successfully")
            print(f"üìä Data Summary: {report['data_summary']['total_days']} days")
            print(f"üí∞ Total Revenue: ${report['data_summary']['total_revenue']:,.2f}")
            print(f"üìà Avg Daily Revenue: ${report['data_summary']['avg_daily_revenue']:,.2f}")
            
            if 'ensemble_forecast' in report and report['ensemble_forecast']:
                forecast_total = sum(report['ensemble_forecast']['forecast_values'])
                print(f"üîÆ 14-day Forecast Total: ${forecast_total:,.2f}")
    
    except Exception as e:
        print(f"‚ùå Test failed: {str(e)}")
